{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d2168e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_daily_US_county_heat_insights=pd.read_csv('E:\\\\Google_Heat\\\\Dataset_to_share\\\\Copy of daily_US_county_heat_insights.csv', sep=\",\")\n",
    "df0 = pd.read_csv(\"E:\\\\Google_Heat\\\\uscounties.csv\", sep=\",\")\n",
    "#df0=df0[~df0['County Name'].str.contains('King')]\n",
    "#df0['County Name'] = df0['County Name']+' County'\n",
    "df_daily_US_county_heat_insights\n",
    "\n",
    "df0.rename(columns={'county_full': 'sub_region_2'}, inplace=True)\n",
    "df0.rename(columns={'state_name': 'sub_region_1'}, inplace=True)\n",
    "df0\n",
    "\n",
    "merged_df = df_daily_US_county_heat_insights.merge(df0[['sub_region_2','sub_region_1', 'lat', 'lng']], on=['sub_region_2','sub_region_1'], how='left')\n",
    "\n",
    "unique_dates = merged_df['date'].unique()\n",
    "\n",
    "df_list = []\n",
    "\n",
    "# Create dataframes for each unique date\n",
    "for date in unique_dates:\n",
    "    df = merged_df[merged_df['date'] == date].copy()\n",
    "    df_list.append(df)\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab49fd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ddf7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily_US_county_heat_insights['date'] = pd.to_datetime(df_daily_US_county_heat_insights['date'])\n",
    "df_daily_US_county_heat_insights[df_daily_US_county_heat_insights['sub_region_2_code']==6037.0]['date'][191]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b66e806",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have a DataFrame called 'df' with a column 'state_column' containing state names\n",
    "\n",
    "# Mapping dictionary for state abbreviations\n",
    "state_abbreviations = {\n",
    "    'Alabama': 'AL', 'Alaska': 'AK', 'Arizona': 'AZ', 'Arkansas': 'AR', 'California': 'CA',\n",
    "    'Colorado': 'CO', 'Connecticut': 'CT', 'Delaware': 'DE', 'Florida': 'FL', 'Georgia': 'GA',\n",
    "    'Hawaii': 'HI', 'Idaho': 'ID', 'Illinois': 'IL', 'Indiana': 'IN', 'Iowa': 'IA',\n",
    "    'Kansas': 'KS', 'Kentucky': 'KY', 'Louisiana': 'LA', 'Maine': 'ME', 'Maryland': 'MD',\n",
    "    'Massachusetts': 'MA', 'Michigan': 'MI', 'Minnesota': 'MN', 'Mississippi': 'MS', 'Missouri': 'MO',\n",
    "    'Montana': 'MT', 'Nebraska': 'NE', 'Nevada': 'NV', 'New Hampshire': 'NH', 'New Jersey': 'NJ',\n",
    "    'New Mexico': 'NM', 'New York': 'NY', 'North Carolina': 'NC', 'North Dakota': 'ND', 'Ohio': 'OH',\n",
    "    'Oklahoma': 'OK', 'Oregon': 'OR', 'Pennsylvania': 'PA', 'Rhode Island': 'RI', 'South Carolina': 'SC',\n",
    "    'South Dakota': 'SD', 'Tennessee': 'TN', 'Texas': 'TX', 'Utah': 'UT', 'Vermont': 'VT',\n",
    "    'Virginia': 'VA', 'Washington': 'WA', 'West Virginia': 'WV', 'Wisconsin': 'WI', 'Wyoming': 'WY'\n",
    "}\n",
    "\n",
    "# Convert state names to abbreviations\n",
    "df_daily_US_county_heat_insights['sub_region_1'] = df_daily_US_county_heat_insights['sub_region_1'].map(state_abbreviations)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "df_daily_US_county_heat_insights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31fdbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily_US_county_heat_insights['sub_region_2']=df_daily_US_county_heat_insights['sub_region_1']+': '+df_daily_US_county_heat_insights['sub_region_2'].str.replace(' County', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d903c7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "new_df = pd.DataFrame()\n",
    "\n",
    "# Iterate over each DataFrame in df_list\n",
    "for i, df in enumerate(df_list[0:5]):\n",
    "    # Extract the \"heat_all\" column from the current DataFrame\n",
    "    print(len(df))\n",
    "    #column_name = f\"Column_{i+1}\"\n",
    "    #new_df[column_name] = list(df[\"heat_all\"].values)\n",
    "\n",
    "#new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f597aa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily_US_county_heat_insights['sub_region_2_code']==1001.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81330e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a list of dataframes called df_list\n",
    "\n",
    "max_values = []\n",
    "max_lat = []\n",
    "max_lng = []\n",
    "max_date=[]\n",
    "for df in df_list:\n",
    "    max_value = df['heat_all'].max()  # Maximum value of 'heat_all' column\n",
    "    max_index = df['heat_all'].idxmax()  # Index of the maximum value\n",
    "    \n",
    "    # Retrieve corresponding values from 'lat' and 'lng' columns\n",
    "    lat_value = df.loc[max_index, 'lat']\n",
    "    lng_value = df.loc[max_index, 'lng']\n",
    "    date_value = df.loc[max_index, 'date']\n",
    "    max_values.append(max_value)\n",
    "    max_lat.append(lat_value)\n",
    "    max_lng.append(lng_value)\n",
    "    max_date.append(date_value)\n",
    "\n",
    "# Create a new dataframe with the maximum values and corresponding lat/lng values\n",
    "result_df = pd.DataFrame({'Max_Date': max_date,'Max_Heat_All': max_values, 'Max_Lat': max_lat, 'Max_Lng': max_lng})\n",
    "\n",
    "# Save the dataframe as a CSV file\n",
    "result_df.to_csv('max_values.csv', index=False)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have the dataframe result_df\n",
    "\n",
    "# Plotting the values in a 2D scatter plot\n",
    "plt.scatter(result_df['Max_Lng'], result_df['Max_Lat'], c=result_df['Max_Heat_All'], cmap='jet')\n",
    "plt.colorbar(label='Max Heat All')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('Maximum Heat All Values')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import levy\n",
    "\n",
    "# Remove rows with missing or non-finite values\n",
    "result_df_cleaned = result_df.dropna(subset=['Max_Lat', 'Max_Lng'])\n",
    "\n",
    "# Calculate the step lengths\n",
    "latitudes = result_df_cleaned['Max_Lat'].astype(float)\n",
    "longitudes = result_df_cleaned['Max_Lng'].astype(float)\n",
    "step_lengths = np.sqrt((latitudes.diff()**2) + (longitudes.diff()**2))\n",
    "\n",
    "# Visualize the step length distribution\n",
    "plt.hist(step_lengths, bins='auto', density=True, alpha=0.7)\n",
    "plt.xlabel('Step Length')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.title('Step Length Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Calculate summary statistics\n",
    "mean_length = step_lengths.mean()\n",
    "median_length = step_lengths.median()\n",
    "std_length = step_lengths.std()\n",
    "\n",
    "# Fit a Levy distribution\n",
    "params = levy.fit(step_lengths[1:]+0.001)\n",
    "best_fit = levy(*params)\n",
    "\n",
    "# Perform a power-law analysis\n",
    "x = np.sort(step_lengths[1:])\n",
    "y = np.arange(1, len(x) + 1) / len(x)\n",
    "\n",
    "plt.loglog(x, y, marker='.', linestyle='none')\n",
    "plt.xlabel('Step Length')\n",
    "plt.ylabel('Probability (log scale)')\n",
    "plt.title('Power-law Analysis')\n",
    "plt.show()\n",
    "\n",
    "# Print the results\n",
    "print(\"Summary Statistics:\")\n",
    "print(f\"Mean: {mean_length}\")\n",
    "print(f\"Median: {median_length}\")\n",
    "print(f\"Standard Deviation: {std_length}\")\n",
    "print(\"\\nLevy Distribution Parameters:\")\n",
    "print(f\"Alpha: {params[0]}\")\n",
    "print(f\"Location: {params[1]}\")\n",
    "step_lengths_heat_all=step_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145cba4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_values = []\n",
    "max_lat = []\n",
    "max_lng = []\n",
    "max_date=[]\n",
    "for df in df_list:\n",
    "    max_value = df['heat_general_info'].max()  # Maximum value of 'heat_all' column\n",
    "    max_index = df['heat_general_info'].idxmax()  # Index of the maximum value\n",
    "    \n",
    "    # Retrieve corresponding values from 'lat' and 'lng' columns\n",
    "    lat_value = df.loc[max_index, 'lat']\n",
    "    lng_value = df.loc[max_index, 'lng']\n",
    "    date_value = df.loc[max_index, 'date']\n",
    "    max_values.append(max_value)\n",
    "    max_lat.append(lat_value)\n",
    "    max_lng.append(lng_value)\n",
    "    max_date.append(date_value)\n",
    "\n",
    "# Create a new dataframe with the maximum values and corresponding lat/lng values\n",
    "result_df = pd.DataFrame({'Max_Date': max_date,'Max_Heat_All': max_values, 'Max_Lat': max_lat, 'Max_Lng': max_lng})\n",
    "\n",
    "# Save the dataframe as a CSV file\n",
    "result_df.to_csv('max_values.csv', index=False)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have the dataframe result_df\n",
    "\n",
    "# Plotting the values in a 2D scatter plot\n",
    "plt.scatter(result_df['Max_Lng'], result_df['Max_Lat'], c=result_df['Max_Heat_All'], cmap='jet')\n",
    "plt.colorbar(label='Max Heat All')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('Maximum Heat All Values')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import levy\n",
    "\n",
    "# Remove rows with missing or non-finite values\n",
    "result_df_cleaned = result_df.dropna(subset=['Max_Lat', 'Max_Lng'])\n",
    "\n",
    "# Calculate the step lengths\n",
    "latitudes = result_df_cleaned['Max_Lat']\n",
    "longitudes = result_df_cleaned['Max_Lng']\n",
    "step_lengths = np.sqrt((latitudes.diff()**2) + (longitudes.diff()**2))\n",
    "\n",
    "# Visualize the step length distribution\n",
    "plt.hist(step_lengths, bins='auto', density=True, alpha=0.7)\n",
    "plt.xlabel('Step Length')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.title('Step Length Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Calculate summary statistics\n",
    "mean_length = step_lengths.mean()\n",
    "median_length = step_lengths.median()\n",
    "std_length = step_lengths.std()\n",
    "\n",
    "# Fit a Levy distribution\n",
    "params = levy.fit(step_lengths[1:])\n",
    "best_fit = levy(*params)\n",
    "\n",
    "# Perform a power-law analysis\n",
    "x = np.sort(step_lengths[1:])\n",
    "y = np.arange(1, len(x) + 1) / len(x)\n",
    "\n",
    "plt.loglog(x, y, marker='.', linestyle='none')\n",
    "plt.xlabel('Step Length')\n",
    "plt.ylabel('Probability (log scale)')\n",
    "plt.title('Power-law Analysis')\n",
    "plt.show()\n",
    "\n",
    "# Print the results\n",
    "print(\"Summary Statistics:\")\n",
    "print(f\"Mean: {mean_length}\")\n",
    "print(f\"Median: {median_length}\")\n",
    "print(f\"Standard Deviation: {std_length}\")\n",
    "print(\"\\nLevy Distribution Parameters:\")\n",
    "print(f\"Alpha: {params[0]}\")\n",
    "print(f\"Location: {params[1]}\")\n",
    "step_lengths_heat_general_info=step_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cbbf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31049a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_values = []\n",
    "max_lat = []\n",
    "max_lng = []\n",
    "max_date=[]\n",
    "for df in df_list:\n",
    "    max_value = df['heat_illness'].max()  # Maximum value of 'heat_all' column\n",
    "    max_index = df['heat_illness'].idxmax()  # Index of the maximum value\n",
    "    \n",
    "    # Retrieve corresponding values from 'lat' and 'lng' columns\n",
    "    lat_value = df.loc[max_index, 'lat']\n",
    "    lng_value = df.loc[max_index, 'lng']\n",
    "    date_value = df.loc[max_index, 'date']\n",
    "    max_values.append(max_value)\n",
    "    max_lat.append(lat_value)\n",
    "    max_lng.append(lng_value)\n",
    "    max_date.append(date_value)\n",
    "\n",
    "# Create a new dataframe with the maximum values and corresponding lat/lng values\n",
    "result_df = pd.DataFrame({'Max_Date': max_date,'Max_Heat_All': max_values, 'Max_Lat': max_lat, 'Max_Lng': max_lng})\n",
    "\n",
    "# Save the dataframe as a CSV file\n",
    "result_df.to_csv('max_values.csv', index=False)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have the dataframe result_df\n",
    "\n",
    "# Plotting the values in a 2D scatter plot\n",
    "plt.scatter(result_df['Max_Lng'], result_df['Max_Lat'], c=result_df['Max_Heat_All'], cmap='jet')\n",
    "plt.colorbar(label='Max Heat All')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('Maximum Heat All Values')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import levy\n",
    "\n",
    "# Remove rows with missing or non-finite values\n",
    "result_df_cleaned = result_df.dropna(subset=['Max_Lat', 'Max_Lng'])\n",
    "\n",
    "# Calculate the step lengths\n",
    "latitudes = result_df_cleaned['Max_Lat']\n",
    "longitudes = result_df_cleaned['Max_Lng']\n",
    "step_lengths = np.sqrt((latitudes.diff()**2) + (longitudes.diff()**2))\n",
    "\n",
    "# Visualize the step length distribution\n",
    "plt.hist(step_lengths, bins='auto', density=True, alpha=0.7)\n",
    "plt.xlabel('Step Length')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.title('Step Length Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Calculate summary statistics\n",
    "mean_length = step_lengths.mean()\n",
    "median_length = step_lengths.median()\n",
    "std_length = step_lengths.std()\n",
    "\n",
    "# Fit a Levy distribution\n",
    "params = levy.fit(step_lengths[1:])\n",
    "best_fit = levy(*params)\n",
    "\n",
    "# Perform a power-law analysis\n",
    "x = np.sort(step_lengths[1:])\n",
    "y = np.arange(1, len(x) + 1) / len(x)\n",
    "\n",
    "plt.loglog(x, y, marker='.', linestyle='none')\n",
    "plt.xlabel('Step Length')\n",
    "plt.ylabel('Probability (log scale)')\n",
    "plt.title('Power-law Analysis')\n",
    "plt.show()\n",
    "\n",
    "# Print the results\n",
    "print(\"Summary Statistics:\")\n",
    "print(f\"Mean: {mean_length}\")\n",
    "print(f\"Median: {median_length}\")\n",
    "print(f\"Standard Deviation: {std_length}\")\n",
    "print(\"\\nLevy Distribution Parameters:\")\n",
    "print(f\"Alpha: {params[0]}\")\n",
    "print(f\"Location: {params[1]}\")\n",
    "step_lengths_heat_illness=step_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419a0de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_values = []\n",
    "max_lat = []\n",
    "max_lng = []\n",
    "max_date=[]\n",
    "for df in df_list:\n",
    "    max_value = df['heat_stroke_and_exhaustion'].max()  # Maximum value of 'heat_all' column\n",
    "    max_index = df['heat_stroke_and_exhaustion'].idxmax()  # Index of the maximum value\n",
    "    \n",
    "    # Retrieve corresponding values from 'lat' and 'lng' columns\n",
    "    lat_value = df.loc[max_index, 'lat']\n",
    "    lng_value = df.loc[max_index, 'lng']\n",
    "    date_value = df.loc[max_index, 'date']\n",
    "    max_values.append(max_value)\n",
    "    max_lat.append(lat_value)\n",
    "    max_lng.append(lng_value)\n",
    "    max_date.append(date_value)\n",
    "\n",
    "# Create a new dataframe with the maximum values and corresponding lat/lng values\n",
    "result_df = pd.DataFrame({'Max_Date': max_date,'Max_Heat_All': max_values, 'Max_Lat': max_lat, 'Max_Lng': max_lng})\n",
    "\n",
    "# Save the dataframe as a CSV file\n",
    "result_df.to_csv('max_values.csv', index=False)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have the dataframe result_df\n",
    "\n",
    "# Plotting the values in a 2D scatter plot\n",
    "plt.scatter(result_df['Max_Lng'], result_df['Max_Lat'], c=result_df['Max_Heat_All'], cmap='jet')\n",
    "plt.colorbar(label='Max Heat All')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('Maximum Heat All Values')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import levy\n",
    "\n",
    "# Remove rows with missing or non-finite values\n",
    "result_df_cleaned = result_df.dropna(subset=['Max_Lat', 'Max_Lng'])\n",
    "\n",
    "# Calculate the step lengths\n",
    "latitudes = result_df_cleaned['Max_Lat']\n",
    "longitudes = result_df_cleaned['Max_Lng']\n",
    "step_lengths = np.sqrt((latitudes.diff()**2) + (longitudes.diff()**2))\n",
    "\n",
    "# Visualize the step length distribution\n",
    "plt.hist(step_lengths, bins='auto', density=True, alpha=0.7)\n",
    "plt.xlabel('Step Length')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.title('Step Length Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Calculate summary statistics\n",
    "mean_length = step_lengths.mean()\n",
    "median_length = step_lengths.median()\n",
    "std_length = step_lengths.std()\n",
    "\n",
    "# Fit a Levy distribution\n",
    "params = levy.fit(step_lengths[1:])\n",
    "best_fit = levy(*params)\n",
    "\n",
    "# Perform a power-law analysis\n",
    "x = np.sort(step_lengths[1:])\n",
    "y = np.arange(1, len(x) + 1) / len(x)\n",
    "\n",
    "plt.loglog(x, y, marker='.', linestyle='none')\n",
    "plt.xlabel('Step Length')\n",
    "plt.ylabel('Probability (log scale)')\n",
    "plt.title('Power-law Analysis')\n",
    "plt.show()\n",
    "\n",
    "# Print the results\n",
    "print(\"Summary Statistics:\")\n",
    "print(f\"Mean: {mean_length}\")\n",
    "print(f\"Median: {median_length}\")\n",
    "print(f\"Standard Deviation: {std_length}\")\n",
    "print(\"\\nLevy Distribution Parameters:\")\n",
    "print(f\"Alpha: {params[0]}\")\n",
    "print(f\"Location: {params[1]}\")\n",
    "step_lengths_heat_stroke_and_exhaustion=step_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19ba91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_values = []\n",
    "max_lat = []\n",
    "max_lng = []\n",
    "max_date=[]\n",
    "for df in df_list:\n",
    "    max_value = df['heat_air_conditioning'].max()  # Maximum value of 'heat_all' column\n",
    "    max_index = df['heat_air_conditioning'].idxmax()  # Index of the maximum value\n",
    "    \n",
    "    # Retrieve corresponding values from 'lat' and 'lng' columns\n",
    "    lat_value = df.loc[max_index, 'lat']\n",
    "    lng_value = df.loc[max_index, 'lng']\n",
    "    date_value = df.loc[max_index, 'date']\n",
    "    max_values.append(max_value)\n",
    "    max_lat.append(lat_value)\n",
    "    max_lng.append(lng_value)\n",
    "    max_date.append(date_value)\n",
    "\n",
    "# Create a new dataframe with the maximum values and corresponding lat/lng values\n",
    "result_df = pd.DataFrame({'Max_Date': max_date,'Max_Heat_All': max_values, 'Max_Lat': max_lat, 'Max_Lng': max_lng})\n",
    "\n",
    "# Save the dataframe as a CSV file\n",
    "result_df.to_csv('max_values.csv', index=False)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have the dataframe result_df\n",
    "\n",
    "# Plotting the values in a 2D scatter plot\n",
    "plt.scatter(result_df['Max_Lng'], result_df['Max_Lat'], c=result_df['Max_Heat_All'], cmap='jet')\n",
    "plt.colorbar(label='Max Heat All')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('Maximum Heat All Values')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import levy\n",
    "\n",
    "# Remove rows with missing or non-finite values\n",
    "result_df_cleaned = result_df.dropna(subset=['Max_Lat', 'Max_Lng'])\n",
    "\n",
    "# Calculate the step lengths\n",
    "latitudes = result_df_cleaned['Max_Lat']\n",
    "longitudes = result_df_cleaned['Max_Lng']\n",
    "step_lengths = np.sqrt((latitudes.diff()**2) + (longitudes.diff()**2))\n",
    "step_lengths_heat_air_conditioning = step_lengths\n",
    "# Visualize the step length distribution\n",
    "plt.hist(step_lengths, bins='auto', density=True, alpha=0.7)\n",
    "plt.xlabel('Step Length')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.title('Step Length Distribution')\n",
    "plt.show()\n",
    "\n",
    "# Calculate summary statistics\n",
    "mean_length = step_lengths.mean()\n",
    "median_length = step_lengths.median()\n",
    "std_length = step_lengths.std()\n",
    "\n",
    "# Fit a Levy distribution\n",
    "params = levy.fit(step_lengths[1:])\n",
    "best_fit = levy(*params)\n",
    "\n",
    "# Perform a power-law analysis\n",
    "x = np.sort(step_lengths[1:])\n",
    "y = np.arange(1, len(x) + 1) / len(x)\n",
    "\n",
    "plt.loglog(x, y, marker='.', linestyle='none')\n",
    "plt.xlabel('Step Length')\n",
    "plt.ylabel('Probability (log scale)')\n",
    "plt.title('Power-law Analysis')\n",
    "plt.show()\n",
    "\n",
    "# Print the results\n",
    "print(\"Summary Statistics:\")\n",
    "print(f\"Mean: {mean_length}\")\n",
    "print(f\"Median: {median_length}\")\n",
    "print(f\"Standard Deviation: {std_length}\")\n",
    "print(\"\\nLevy Distribution Parameters:\")\n",
    "print(f\"Alpha: {params[0]}\")\n",
    "print(f\"Location: {params[1]}\")\n",
    "fig = plt.figure(figsize=(18, 6))\n",
    "\n",
    "plt.plot(step_lengths[1:])\n",
    "step_lengths_heat_air_conditioning=step_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c007b249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import levy\n",
    "\n",
    "# Assuming you have a dataset called 'data' that represents step lengths\n",
    "\n",
    "# Fit the dataset to a Levy distribution using Maximum Likelihood Estimation (MLE)\n",
    "params = levy.fit(step_lengths[1:])  # loc=0 assumes a starting point at the origin\n",
    "\n",
    "# Extract the estimated shape parameter (alpha) and scale parameter (c)\n",
    "shape_parameter = params[0]\n",
    "scale_parameter = params[1]\n",
    "\n",
    "# Print the estimated parameters\n",
    "print(\"Estimated Parameters:\")\n",
    "print(f\"Shape Parameter (alpha): {shape_parameter}\")\n",
    "print(f\"Scale Parameter (c): {scale_parameter}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb86c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import glob\n",
    "import os\n",
    "\n",
    "lframes = []\n",
    "for idf in range(0, 730):\n",
    "    mean_value = df_list[idf]['heat_general_info'].mean()\n",
    "    filtered_df = df_list[idf][df_list[idf]['heat_general_info'] > mean_value]\n",
    "\n",
    "    frame_data = go.Scatter(\n",
    "        x=filtered_df['lng'],\n",
    "        y=filtered_df['lat'],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=6,\n",
    "            color=filtered_df['heat_general_info'],\n",
    "            colorscale='Viridis',\n",
    "            opacity=0.4,\n",
    "            colorbar=dict(thickness=10, orientation='h')\n",
    "        )\n",
    "    )\n",
    "\n",
    "    annotation = dict(\n",
    "        text=f\"Date: {unique_dates[idf]}\",\n",
    "        showarrow=False,\n",
    "        xref=\"paper\",\n",
    "        yref=\"paper\",\n",
    "        x=0.05,\n",
    "        y=0.05,\n",
    "        bgcolor=\"white\",\n",
    "        opacity=0.8\n",
    "    )\n",
    "\n",
    "    lframes.append(go.Frame(data=[frame_data], name=f\"Date: {unique_dates[idf]}\", layout=go.Layout(annotations=[annotation])))\n",
    "\n",
    "fig = go.Figure(\n",
    "    data=[go.Scatter(\n",
    "        x=filtered_df['lng'],\n",
    "        y=filtered_df['lat'],\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            symbol='square',\n",
    "            size=6,\n",
    "            color=filtered_df['heat_general_info'],\n",
    "            colorscale='Viridis',\n",
    "            opacity=0.4,\n",
    "            colorbar=dict(thickness=10, orientation='h')\n",
    "        )\n",
    "    )],\n",
    "    layout=go.Layout(\n",
    "        xaxis=dict(range=[min(filtered_df['lng']), max(filtered_df['lat'])], autorange=True),\n",
    "        yaxis=dict(range=[min(filtered_df['lng']), max(filtered_df['lat'])], autorange=True),\n",
    "        sliders=[dict(\n",
    "            active=0,\n",
    "            currentvalue=dict(\n",
    "                prefix=\"Frame: \",\n",
    "                font=dict(color=\"#666\"),\n",
    "                xanchor=\"left\",\n",
    "                visible=True,\n",
    "                offset=10\n",
    "            ),\n",
    "            pad=dict(t=50),\n",
    "            len=0.9,\n",
    "            x=0.1,\n",
    "            y=0,\n",
    "            steps=[dict(\n",
    "                method=\"animate\",\n",
    "                args=[[f\"Date: {unique_dates[idf]}\"], {\"frame\": {\"duration\": 0, \"redraw\": False}, \"mode\": \"immediate\"}],\n",
    "                label=f\"Date: {unique_dates[idf]}\"\n",
    "            ) for idf in range(365)]\n",
    "        )],\n",
    "        updatemenus=[\n",
    "            dict(\n",
    "                type=\"buttons\",\n",
    "                buttons=[\n",
    "                    dict(\n",
    "                        label=\"Play\",\n",
    "                        method=\"animate\",\n",
    "                        args=[None]\n",
    "                    ),\n",
    "                    dict(\n",
    "                        label=\"Pause\",\n",
    "                        method=\"animate\",\n",
    "                        args=[[None], {\"frame\": {\"duration\": 0, \"redraw\": False}, \"mode\": \"immediate\"}]\n",
    "                    )\n",
    "                ]\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    frames=lframes\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    width=1100,\n",
    "    height=800\n",
    ")\n",
    "fig.write_html('us_heat_general_info.html')\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c587e534",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae65e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df['Max_Date'] = pd.to_datetime(result_df['Max_Date'])\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350e42cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18, 6))\n",
    "\n",
    "plt.plot(step_lengths_heat_all)\n",
    "plt.plot(step_lengths_heat_general_info)\n",
    "plt.plot(step_lengths_heat_illness)\n",
    "plt.plot(step_lengths_heat_stroke_and_exhaustion)\n",
    "plt.plot(step_lengths_heat_air_conditioning)\n",
    "\n",
    "\n",
    "array1 = np.array(list(step_lengths_heat_all[1:]))\n",
    "array2 = np.array(list(step_lengths_heat_general_info[1:]))\n",
    "array3 = np.array(list(step_lengths_heat_illness[1:]))\n",
    "array4 = np.array(list(step_lengths_heat_stroke_and_exhaustion[1:]))\n",
    "array5 = np.array(list(step_lengths_heat_air_conditioning[1:]))\n",
    "\n",
    "print(\"Correlation step_lengths_heat_all, step_lengths_heat_general_info:  \")\n",
    "correlation = np.corrcoef(array1, array2)[0, 1]\n",
    "print(correlation)\n",
    "correlation = np.corrcoef(array1, array3)[0, 1]\n",
    "print(\"Correlation step_lengths_heat_all, step_lengths_heat_illness:  \")\n",
    "print(correlation)\n",
    "correlation = np.corrcoef(array1, array4)[0, 1]\n",
    "print(\"Correlation step_lengths_heat_all, step_lengths_heat_stroke_and_exhaustion:  \")\n",
    "print(correlation)\n",
    "correlation = np.corrcoef(array1, array5)[0, 1]\n",
    "print(\"Correlation step_lengths_heat_all, step_lengths_heat_air_conditioning:  \")\n",
    "print(correlation)\n",
    "\n",
    "\n",
    "correlation = np.corrcoef(array2, array3)[0, 1]\n",
    "print(\"Correlation step_lengths_heat_general_info, step_lengths_heat_illness:  \")\n",
    "print(correlation)\n",
    "correlation = np.corrcoef(array2, array4)[0, 1]\n",
    "print(\"Correlation step_lengths_heat_general_info, step_lengths_heat_stroke_and_exhaustion:  \")\n",
    "print(correlation)\n",
    "correlation = np.corrcoef(array2, array5)[0, 1]\n",
    "print(\"Correlation step_lengths_heat_general_info, step_lengths_heat_air_conditioning:  \")\n",
    "print(correlation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76a4f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6fefd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(step_lengths_heat_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f3796f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Assuming you have the 'result_df' DataFrame and 'step_lengths' time series\n",
    "\n",
    "# Convert 'Max_Date' to datetime format\n",
    "\n",
    "# Set up the figure and axes\n",
    "fig, ax = plt.subplots(figsize=(18, 6))\n",
    "\n",
    "# Plot the scatter plot with different colors for each weekday\n",
    "scatter = ax.scatter(result_df['Max_Date'][1:], step_lengths_heat_general_info[1:], c=result_df['Max_Date'][1:].dt.weekday, cmap='viridis')\n",
    "\n",
    "# Set x-axis label and tick format\n",
    "ax.set_xlabel('Date')\n",
    "ax.xaxis.set_major_locator(mdates.WeekdayLocator())\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "\n",
    "# Set y-axis label\n",
    "ax.set_ylabel('Step Length')\n",
    "\n",
    "# Add colorbar\n",
    "cbar = plt.colorbar(scatter, ticks=range(7))\n",
    "cbar.set_label('Weekday')\n",
    "cbar.set_ticklabels(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])\n",
    "\n",
    "# Rotate x-axis labels if needed\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06a3cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# simple code to implement Runs \n",
    "# test of randomnes\n",
    "#Compare the value of the calculated Z-statistic with Zcritical  for a given level of confidence (Zcritical =1.96 for \n",
    "#confidence level of 95%) . he null hypothesis is rejected i.e. the numbers are declared not to be random, if |Z|>Zcritical.            \n",
    "import random\n",
    "import math\n",
    "import statistics\n",
    "  \n",
    "  \n",
    "def runsTest(l, l_median):\n",
    "  \n",
    "    runs, n1, n2 = 0, 0, 0\n",
    "      \n",
    "    # Checking for start of new run\n",
    "    for i in range(len(l)):\n",
    "          \n",
    "        # no. of runs\n",
    "        if (l[i] >= l_median and l[i-1] < l_median) or \\\n",
    "                (l[i] < l_median and l[i-1] >= l_median):\n",
    "            runs += 1  \n",
    "          \n",
    "        # no. of positive values\n",
    "        if(l[i]) >= l_median:\n",
    "            n1 += 1   \n",
    "          \n",
    "        # no. of negative values\n",
    "        else:\n",
    "            n2 += 1   \n",
    "  \n",
    "    runs_exp = ((2*n1*n2)/(n1+n2))+1\n",
    "    stan_dev = math.sqrt((2*n1*n2*(2*n1*n2-n1-n2))/ \\\n",
    "                       (((n1+n2)**2)*(n1+n2-1)))\n",
    "  \n",
    "    z = (runs-runs_exp)/stan_dev\n",
    "  \n",
    "    return z\n",
    "    \n",
    "l = list(step_lengths[1:])\n",
    "      \n",
    "l_median= statistics.median(l)\n",
    "  \n",
    "Z = abs(runsTest(l, l_median))\n",
    "  \n",
    "print('Z-statistic= ', Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cac5a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: UTF-8 -*-\n",
    "###                   https://github.com/Mottl/hurst/tree/master\n",
    "\"\"\"\n",
    "Hurst exponent and RS-analysis\n",
    "https://en.wikipedia.org/wiki/Hurst_exponent\n",
    "https://en.wikipedia.org/wiki/Rescaled_range\n",
    "\"\"\"\n",
    "\n",
    "name = \"hurst\"\n",
    "__version__ = '0.0.5'\n",
    "\n",
    "import sys\n",
    "import math\n",
    "import warnings\n",
    "import numpy as np\n",
    "try:\n",
    "    import pandas as pd\n",
    "except:\n",
    "    pass\n",
    "\n",
    "def __to_inc(x):\n",
    "    incs = x[1:] - x[:-1]\n",
    "    return incs\n",
    "\n",
    "def __to_pct(x):\n",
    "    pcts = x[1:] / x[:-1] - 1.\n",
    "    return pcts\n",
    "\n",
    "def __get_simplified_RS(series, kind):\n",
    "    \"\"\"\n",
    "    Simplified version of rescaled range\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    series : array-like\n",
    "        (Time-)series\n",
    "    kind : str\n",
    "        The kind of series (refer to compute_Hc docstring)\n",
    "    \"\"\"\n",
    "\n",
    "    if kind == 'random_walk':\n",
    "        incs = __to_inc(series)\n",
    "        R = max(series) - min(series)  # range in absolute values\n",
    "        S = np.std(incs, ddof=1)\n",
    "    elif kind == 'price':\n",
    "        pcts = __to_pct(series)\n",
    "        R = max(series) / min(series) - 1. # range in percent\n",
    "        S = np.std(pcts, ddof=1)\n",
    "    elif kind == 'change':\n",
    "        incs = series\n",
    "        _series = np.hstack([[0.],np.cumsum(incs)])\n",
    "        R = max(_series) - min(_series)  # range in absolute values\n",
    "        S = np.std(incs, ddof=1)\n",
    "\n",
    "    if R == 0 or S == 0:\n",
    "        return 0  # return 0 to skip this interval due the undefined R/S ratio\n",
    "\n",
    "    return R / S\n",
    "\n",
    "def __get_RS(series, kind):\n",
    "    \"\"\"\n",
    "    Get rescaled range (using the range of cumulative sum\n",
    "    of deviations instead of the range of a series as in the simplified version\n",
    "    of R/S) from a time-series of values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    series : array-like\n",
    "        (Time-)series\n",
    "    kind : str\n",
    "        The kind of series (refer to compute_Hc docstring)\n",
    "    \"\"\"\n",
    "\n",
    "    if kind == 'random_walk':\n",
    "        incs = __to_inc(series)\n",
    "        mean_inc = (series[-1] - series[0]) / len(incs)\n",
    "        deviations = incs - mean_inc\n",
    "        Z = np.cumsum(deviations)\n",
    "        R = max(Z) - min(Z)\n",
    "        S = np.std(incs, ddof=1)\n",
    "\n",
    "    elif kind == 'price':\n",
    "        incs = __to_pct(series)\n",
    "        mean_inc = np.sum(incs) / len(incs)\n",
    "        deviations = incs - mean_inc\n",
    "        Z = np.cumsum(deviations)\n",
    "        R = max(Z) - min(Z)\n",
    "        S = np.std(incs, ddof=1)\n",
    "\n",
    "    elif kind == 'change':\n",
    "        incs = series\n",
    "        mean_inc = np.sum(incs) / len(incs)\n",
    "        deviations = incs - mean_inc\n",
    "        Z = np.cumsum(deviations)\n",
    "        R = max(Z) - min(Z)\n",
    "        S = np.std(incs, ddof=1)\n",
    "\n",
    "    if R == 0 or S == 0:\n",
    "        return 0  # return 0 to skip this interval due undefined R/S\n",
    "\n",
    "    return R / S\n",
    "\n",
    "def compute_Hc(series, kind=\"random_walk\", min_window=3, max_window=300, simplified=True):\n",
    "    \"\"\"\n",
    "    Compute H (Hurst exponent) and C according to Hurst equation:\n",
    "    E(R/S) = c * T^H\n",
    "\n",
    "    Refer to:\n",
    "    https://en.wikipedia.org/wiki/Hurst_exponent\n",
    "    https://en.wikipedia.org/wiki/Rescaled_range\n",
    "    https://en.wikipedia.org/wiki/Random_walk\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    series : array-like\n",
    "        (Time-)series\n",
    "\n",
    "    kind : str\n",
    "        Kind of series\n",
    "        possible values are 'random_walk', 'change' and 'price':\n",
    "        - 'random_walk' means that a series is a random walk with random increments;\n",
    "        - 'price' means that a series is a random walk with random multipliers;\n",
    "        - 'change' means that a series consists of random increments\n",
    "            (thus produced random walk is a cumulative sum of increments);\n",
    "\n",
    "    min_window : int, default 10\n",
    "        the minimal window size for R/S calculation\n",
    "\n",
    "    max_window : int, default is the length of series minus 1\n",
    "        the maximal window size for R/S calculation\n",
    "\n",
    "    simplified : bool, default True\n",
    "        whether to use the simplified or the original version of R/S calculation\n",
    "\n",
    "    Returns tuple of\n",
    "        H, c and data\n",
    "        where H and c — parameters or Hurst equation\n",
    "        and data is a list of 2 lists: time intervals and R/S-values for correspoding time interval\n",
    "        for further plotting log(data[0]) on X and log(data[1]) on Y\n",
    "    \"\"\"\n",
    "\n",
    "    if len(series)<100:\n",
    "        raise ValueError(\"Series length must be greater or equal to 100\")\n",
    "\n",
    "    ndarray_likes = [np.ndarray]\n",
    "    if \"pandas.core.series\" in sys.modules.keys():\n",
    "        ndarray_likes.append(pd.core.series.Series)\n",
    "\n",
    "    # convert series to numpy array if series is not numpy array or pandas Series\n",
    "    if type(series) not in ndarray_likes:\n",
    "        series = np.array(series)\n",
    "\n",
    "    if \"pandas.core.series\" in sys.modules.keys() and type(series) == pd.core.series.Series:\n",
    "        if series.isnull().values.any():\n",
    "            raise ValueError(\"Series contains NaNs\")\n",
    "        series = series.values  # convert pandas Series to numpy array\n",
    "    elif np.isnan(np.min(series)):\n",
    "        raise ValueError(\"Series contains NaNs\")\n",
    "\n",
    "    if simplified:\n",
    "        RS_func = __get_simplified_RS\n",
    "    else:\n",
    "        RS_func = __get_RS\n",
    "\n",
    "\n",
    "    err = np.geterr()\n",
    "    np.seterr(all='raise')\n",
    "\n",
    "    max_window = max_window or len(series)-1\n",
    "    window_sizes = list(map(\n",
    "        lambda x: int(10**x),\n",
    "        np.arange(math.log10(min_window), math.log10(max_window), 0.25)))\n",
    "    window_sizes.append(len(series))\n",
    "\n",
    "    RS = []\n",
    "    for w in window_sizes:\n",
    "        rs = []\n",
    "        for start in range(0, len(series), w):\n",
    "            if (start+w)>len(series):\n",
    "                break\n",
    "            _ = RS_func(series[start:start+w], kind)\n",
    "            if _ != 0:\n",
    "                rs.append(_)\n",
    "        RS.append(np.mean(rs))\n",
    "\n",
    "    A = np.vstack([np.log10(window_sizes), np.ones(len(RS))]).T\n",
    "    H, c = np.linalg.lstsq(A, np.log10(RS), rcond=-1)[0]\n",
    "    np.seterr(**err)\n",
    "\n",
    "    c = 10**c\n",
    "    return H, c, [window_sizes, RS]\n",
    "\n",
    "def random_walk(length, proba=0.5, min_lookback=1, max_lookback=100, cumprod=False):\n",
    "    \"\"\"\n",
    "    Generates a random walk series\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    proba : float, default 0.5\n",
    "        the probability that the next increment will follow the trend.\n",
    "        Set proba > 0.5 for the persistent random walk,\n",
    "        set proba < 0.5 for the antipersistent one\n",
    "\n",
    "    min_lookback: int, default 1\n",
    "    max_lookback: int, default 100\n",
    "        minimum and maximum window sizes to calculate trend direction\n",
    "    cumprod : bool, default False\n",
    "        generate a random walk as a cumulative product instead of cumulative sum\n",
    "    \"\"\"\n",
    "\n",
    "    assert(min_lookback>=1)\n",
    "    assert(max_lookback>=min_lookback)\n",
    "\n",
    "    if max_lookback > length:\n",
    "        max_lookback = length\n",
    "        warnings.warn(\"max_lookback parameter has been set to the length of the random walk series.\")\n",
    "\n",
    "    if not cumprod:  # ordinary increments\n",
    "        series = [0.] * length  # array of prices\n",
    "        for i in range(1, length):\n",
    "            if i < min_lookback + 1:\n",
    "                direction = np.sign(np.random.randn())\n",
    "            else:\n",
    "                lookback = np.random.randint(min_lookback, min(i-1, max_lookback)+1)\n",
    "                direction = np.sign(series[i-1] - series[i-1-lookback]) * np.sign(proba - np.random.uniform())\n",
    "            series[i] = series[i-1] + np.fabs(np.random.randn()) * direction\n",
    "    else:  # percent changes\n",
    "        series = [1.] * length  # array of prices\n",
    "        for i in range(1, length):\n",
    "            if i < min_lookback + 1:\n",
    "                direction = np.sign(np.random.randn())\n",
    "            else:\n",
    "                lookback = np.random.randint(min_lookback, min(i-1, max_lookback)+1)\n",
    "                direction = np.sign(series[i-1] / series[i-1-lookback] - 1.) * np.sign(proba - np.random.uniform())\n",
    "            series[i] = series[i-1] * np.fabs(1 + np.random.randn()/1000. * direction)\n",
    "\n",
    "    return series\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Use random_walk() function or generate a random walk series manually:\n",
    "# series = random_walk(99999, cumprod=True)\n",
    "np.random.seed(42)\n",
    "random_changes = 1. + np.random.randn(99999) / 1000.\n",
    "series = np.cumprod(random_changes)  # create a random walk from random changes\n",
    "\n",
    "# Evaluate Hurst equation\n",
    "H, c, data = compute_Hc(np.array(step_lengths[1:]+0.01), kind='change', simplified=True)\n",
    "\n",
    "# Plot\n",
    "# uncomment the following to make a plot using Matplotlib:\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "ax.plot(data[0], c*data[0]**H, color=\"deepskyblue\")\n",
    "ax.scatter(data[0], data[1], color=\"purple\")\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('Time interval')\n",
    "ax.set_ylabel('R/S ratio')\n",
    "ax.grid(True)\n",
    "plt.show()\n",
    "\"\"\"\n",
    "\n",
    "print(\"H={:.4f}, c={:.4f}\".format(H,c))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59902ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from hurst import compute_Hc, random_walk\n",
    "\n",
    "\n",
    "series = np.array(step_lengths[1:]+0.01)  \n",
    "\n",
    "H, c, data = compute_Hc(series, kind='change', simplified=True)\n",
    "\n",
    "# Plot\n",
    "f, ax = plt.subplots()\n",
    "ax.plot(data[0], c*data[0]**H, color=\"deepskyblue\")\n",
    "ax.scatter(data[0], data[1], color=\"purple\")\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('Time interval')\n",
    "ax.set_ylabel('R/S ratio')\n",
    "ax.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(\"H={:.4f}, c={:.4f}\".format(H,c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e84f084",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pycwt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d53fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "\n",
    "# Assuming you have spatiotemporal data with two variables 'var1' and 'var2'\n",
    "\n",
    "# Set the parameters for the wavelet transform\n",
    "scales = np.arange(1, 10)\n",
    "wavelet_name = 'morl'\n",
    "\n",
    "# Perform the cross wavelet transform\n",
    "cwt_var1, frequencies = pywt.cwt(array1, scales, wavelet_name)\n",
    "cwt_var2, _ = pywt.cwt(array5, scales, wavelet_name)\n",
    "\n",
    "# Plot the cross wavelet transform\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(np.abs(cwt_var1) * np.abs(cwt_var2), aspect='auto', cmap='jet')\n",
    "plt.colorbar(label='Magnitude')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Scale')\n",
    "plt.title('Cross Wavelet Transform')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1ad9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "array1 = np.array(list(step_lengths_heat_all[1:]))\n",
    "array2 = np.array(list(step_lengths_heat_general_info[1:]))\n",
    "result_df_step_lengths_heat_all=result_df.copy()\n",
    "result_df_step_lengths_heat_all['Max_Heat_All']=step_lengths_heat_all\n",
    "result_df_step_lengths_heat_all.rename(columns={'Max_Heat_All': 'heat_all'}, inplace=True)\n",
    "result_df_step_lengths_heat_general_info=result_df.copy()\n",
    "result_df_step_lengths_heat_general_info['Max_Heat_All']=step_lengths_heat_general_info\n",
    "result_df_step_lengths_heat_general_info.rename(columns={'Max_Heat_All': 'heat_general_info'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3765a859",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_step_lengths_heat_general_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc042564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "# Assuming you have temperature and pressure DataFrames\n",
    "result_df_step_lengths_heat_all\n",
    "\n",
    "result_df_step_lengths_heat_general_info\n",
    "# Merge temperature and pressure DataFrames based on common columns\n",
    "merged_df12 = pd.merge(result_df_step_lengths_heat_all, result_df_step_lengths_heat_general_info, on=['Max_Date', 'Max_Lat', 'Max_Lng'])\n",
    "\n",
    "merged_df12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e69dda2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
